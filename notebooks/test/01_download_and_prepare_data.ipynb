{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83280dab",
   "metadata": {},
   "source": [
    "# 01 — Télécharger & préparer le dataset (classe **frelon** uniquement)\n",
    "\n",
    "Ce notebook :\n",
    "1. Télécharge le dataset Roboflow depuis votre compte (vous devez fournir votre `RF_API_KEY`).\n",
    "2. Extrait uniquement la classe **frelon**.\n",
    "3. Construit des annotations *COCO* filtrées (1 seule catégorie) et génère des TFRecords pour la TensorFlow Object Detection API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04e3225",
   "metadata": {},
   "source": [
    "## 1) Paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c499be7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⚠️ À adapter si besoin\n",
    "ROBOFLOW_API_KEY = os.environ.get(\"RF_API_KEY\", \"\")  # ou mettez directement votre clé: \"rf_xxx\"\n",
    "ROBOFLOW_WORKSPACE = \"frelonproject\"\n",
    "ROBOFLOW_PROJECT = \"hornet-bees-6bl4k\"\n",
    "ROBOFLOW_VERSION = 2  # selon votre lien\n",
    "DATA_BASE_DIR = \"data\"  # dossier local où placer les données\n",
    "\n",
    "# Nom de la classe à garder\n",
    "TARGET_CLASS = \"frelon\"\n",
    "\n",
    "os.makedirs(DATA_BASE_DIR, exist_ok=True)\n",
    "print(\"DATA_BASE_DIR:\", os.path.abspath(DATA_BASE_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f47b10b",
   "metadata": {},
   "source": [
    "## 2) Télécharger en format COCO (object detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3219e61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from roboflow import Roboflow\n",
    "assert ROBOFLOW_API_KEY, \"Veuillez renseigner votre clé Roboflow (RF_API_KEY).\"\n",
    "\n",
    "rf = Roboflow(api_key=ROBOFLOW_API_KEY)\n",
    "project = rf.workspace(ROBOFLOW_WORKSPACE).project(ROBOFLOW_PROJECT)\n",
    "version = project.version(ROBOFLOW_VERSION)\n",
    "\n",
    "# Télécharge en COCO pour TF (images + annotations)\n",
    "dataset = version.download(\"coco\")\n",
    "\n",
    "print(\"Dataset local:\", dataset.location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedfbe5d",
   "metadata": {},
   "source": [
    "## 3) Filtrer les annotations à la seule classe **frelon**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab52fa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, shutil, glob, os\n",
    "\n",
    "coco_dirs = {\n",
    "    \"train\": os.path.join(dataset.location, \"train\"),\n",
    "    \"valid\": os.path.join(dataset.location, \"valid\"),\n",
    "    \"test\":  os.path.join(dataset.location, \"test\"),\n",
    "}\n",
    "\n",
    "def filter_coco_to_single_class(coco_json_path, keep_class_name, out_json_path):\n",
    "    with open(coco_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        coco = json.load(f)\n",
    "\n",
    "    # Trouver l'id de la classe à garder\n",
    "    name_to_id = {c[\"name\"]: c[\"id\"] for c in coco[\"categories\"]}\n",
    "    if keep_class_name not in name_to_id:\n",
    "        raise ValueError(f\"Classe '{keep_class_name}' introuvable dans {coco_json_path}.\")\n",
    "\n",
    "    keep_id = name_to_id[keep_class_name]\n",
    "\n",
    "    # Filtrer annotations et images\n",
    "    keep_ann = [a for a in coco[\"annotations\"] if a[\"category_id\"] == keep_id]\n",
    "    keep_img_ids = set(a[\"image_id\"] for a in keep_ann)\n",
    "    keep_imgs   = [img for img in coco[\"images\"] if img[\"id\"] in keep_img_ids]\n",
    "\n",
    "    # Nouvelle catégorie unique\n",
    "    new_cats = [{\n",
    "        \"id\": 1,\n",
    "        \"name\": keep_class_name,\n",
    "        \"supercategory\": keep_class_name\n",
    "    }]\n",
    "\n",
    "    # Remapper category_id -> 1\n",
    "    for a in keep_ann:\n",
    "        a[\"category_id\"] = 1\n",
    "\n",
    "    filtered = {\n",
    "        \"images\": keep_imgs,\n",
    "        \"annotations\": keep_ann,\n",
    "        \"categories\": new_cats\n",
    "    }\n",
    "\n",
    "    with open(out_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(filtered, f, ensure_ascii=False)\n",
    "    return len(keep_imgs), len(keep_ann)\n",
    "\n",
    "for split in [\"train\", \"valid\", \"test\"]:\n",
    "    ann_path = os.path.join(coco_dirs[split], \"_annotations.coco.json\")\n",
    "    out_path = os.path.join(coco_dirs[split], f\"_annotations_single_{TARGET_CLASS}.coco.json\")\n",
    "    n_img, n_ann = filter_coco_to_single_class(ann_path, TARGET_CLASS, out_path)\n",
    "    print(f\"{split}: images gardées={n_img}, annotations gardées={n_ann}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cce7cf",
   "metadata": {},
   "source": [
    "## 4) Générer des TFRecords (TF Object Detection API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0e1b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilise le script officiel create_coco_tf_record.py du repo TF Models.\n",
    "# Le script sera disponible après installation de l'API (voir notebook 02).\n",
    "# Ici, on prépare simplement les chemins et les commandes à exécuter plus tard.\n",
    "\n",
    "TF_MODELS_DIR = \"models\"  # où sera cloné le repo tensorflow/models\n",
    "TF_RECORDS_DIR = os.path.join(DATA_BASE_DIR, \"tfrecords_single_class\")\n",
    "os.makedirs(TF_RECORDS_DIR, exist_ok=True)\n",
    "\n",
    "train_images_dir = os.path.join(coco_dirs[\"train\"])\n",
    "val_images_dir   = os.path.join(coco_dirs[\"valid\"])\n",
    "test_images_dir  = os.path.join(coco_dirs[\"test\"])\n",
    "\n",
    "train_ann = os.path.join(coco_dirs[\"train\"], f\"_annotations_single_{TARGET_CLASS}.coco.json\")\n",
    "val_ann   = os.path.join(coco_dirs[\"valid\"], f\"_annotations_single_{TARGET_CLASS}.coco.json\")\n",
    "\n",
    "print(\"TF_RECORDS_DIR:\", os.path.abspath(TF_RECORDS_DIR))\n",
    "\n",
    "print(\"\"\"\n",
    "Après avoir installé l'API (notebook 02), exécutez **dans un terminal** depuis la racine du repo 'models':\n",
    "\n",
    "python research/object_detection/dataset_tools/create_coco_tf_record.py \\\n",
    "  --logtostderr \\\n",
    "  --train_image_dir {train_images_dir} \\\n",
    "  --val_image_dir {val_images_dir} \\\n",
    "  --test_image_dir {test_images_dir} \\\n",
    "  --train_annotations_file {train_ann} \\\n",
    "  --val_annotations_file {val_ann} \\\n",
    "  --testdev_annotations_file {val_ann} \\\n",
    "  --output_dir {TF_RECORDS_DIR}\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
